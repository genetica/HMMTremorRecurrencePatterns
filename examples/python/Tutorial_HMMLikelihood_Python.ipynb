{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Unit-Test\" data-toc-modified-id=\"Unit-Test-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Unit Test</a></span></li><li><span><a href=\"#Usage-Example\" data-toc-modified-id=\"Usage-Example-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Usage Example</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-Emission-Probability-Function\" data-toc-modified-id=\"Define-Emission-Probability-Function-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Define Emission Probability Function</a></span></li><li><span><a href=\"#Setting-up-an-HMM-Chain\" data-toc-modified-id=\"Setting-up-an-HMM-Chain-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Setting up an HMM Chain</a></span></li><li><span><a href=\"#HMM-Optimisation-using-MCMC\" data-toc-modified-id=\"HMM-Optimisation-using-MCMC-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>HMM Optimisation using MCMC</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T20:17:35.396383Z",
     "start_time": "2020-04-16T20:17:35.394423Z"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook provides insight into how to use the HMMLikelihood library. The library currently provides the capability to calculate the likelihood function of an HMM using OpenCL. \n",
    "The limitations and capability:\n",
    "- Diagonal emission matrix, \n",
    "- Custom emission probability function.\n",
    "- HMM limited to about 80 states.\n",
    "- Developed for very long time sequences (> 10000).\n",
    "\n",
    "The library origin is from work performed in *A 1000-fold Acceleration of Hidden Markov Model Fitting using Graphical Processing Units, with application to Nonvolcanic Tremor Classification* https://arxiv.org/abs/2003.03508\n",
    "\n",
    "It is important to read the comments within each of the code blocks as well as the markdown text. Further in this chapter, all the libraries are imported and OpenCL devices interrogated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:04:55.784677Z",
     "start_time": "2020-04-17T14:04:55.335252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import time\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import scipy.stats as sps\n",
    "\n",
    "# MCMC import\n",
    "import pytwalk\n",
    "\n",
    "# Add HMMLikelihood path to python path\n",
    "import sys\n",
    "sys.path\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:04:55.787720Z",
     "start_time": "2020-04-17T14:04:55.785831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add before importing HMMLikelihood to make opencl vebose\n",
    "import os\n",
    "os.environ['PYOPENCL_COMPILER_OUTPUT'] = '0'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:04:55.940113Z",
     "start_time": "2020-04-17T14:04:55.788950Z"
    }
   },
   "outputs": [],
   "source": [
    "import HMMLikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:04:55.951520Z",
     "start_time": "2020-04-17T14:04:55.941499Z"
    }
   },
   "outputs": [],
   "source": [
    "# Query OpenCL devices.\n",
    "HMMLikelihood.Likelihood().pyOpenCLInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note. \n",
    "\n",
    "In function call `lhfunc = HMMLikelihood.Likelihood` \n",
    "the parameter `platform_id`can be changed to select \n",
    "the correct OpenCL platform. If unsure, default setting is 0.\n",
    "\n",
    "`lhfunc.pyOpenCLInfo()` provide to info on OpenCL platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Test\n",
    "\n",
    "This section test the OpenCL device with accuracy tests and speed tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:05:01.540466Z",
     "start_time": "2020-04-17T14:04:55.953543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Number of data points\n",
    "T = 1000\n",
    "# Number of states\n",
    "dim = 25\n",
    "# Select the OpenCL platform, defautl is 0\n",
    "platform_id = 0\n",
    "# More output\n",
    "beVerbose=False\n",
    "\n",
    "\n",
    "# Files to opencl kernels\n",
    "file_diag_kernel = \"../../HMMLikelihood/prob_function.cl\"\n",
    "file_diag_normal = \"../../HMMLikelihood/diag_normalc.cl\"\n",
    "file_diag_mat_mul = \"../../HMMLikelihood/diag_mat_mulO.cl\"\n",
    "file_matrixmul = \"../../HMMLikelihood/matrixmulT.cl\"\n",
    "#file_diag_normal = \"./clLikelihood/old_diag_normal.cl\"\n",
    "#file_diag_mat_mul = \"./clLikelihood/diag_mat_mulB.cl\"\n",
    "#file_matrixmul = \"./clLikelihood/matrixmulT.cl\"\n",
    "\n",
    "# Calculate random transistion matrix\n",
    "transistion_matrix = HMMLikelihood.calc_transition_matrix(dim)\n",
    "if (beVerbose):\n",
    "    print(\"Transistion Matrix\\n\", transistion_matrix)\n",
    "\n",
    "\n",
    "#Generate random data with dimension of 2\n",
    "data = np.random.random([T,3])\n",
    "data[:,2] = np.round(data[:,2])\n",
    "\n",
    "if (beVerbose):\n",
    "    print(\"Data\\n\")#, data)\n",
    "\n",
    "# Generate kernel with random initialisations\n",
    "kernel = HMMLikelihood.Kernel(\n",
    "           np.random.random([dim,2]), \n",
    "           np.random.random([dim,2]), \n",
    "           np.random.random(dim), \n",
    "           np.random.random(dim), \n",
    "           dim)\n",
    "\n",
    "if (beVerbose):\n",
    "    print(\"Kernels\\n\", kernel())\n",
    "\n",
    "# Create likelhood function\n",
    "lh_func = HMMLikelihood.Likelihood(\n",
    "                        data,                                # Data points  \n",
    "                        transistion_matrix,                  # Transistion matrix initial \n",
    "                        kernel(),                            # Kernel parameters\n",
    "                        file_diag_kernel=file_diag_kernel,   # File to probability function\n",
    "                        file_diag_normal=file_diag_normal,   # File to calculate probability function\n",
    "                        file_diag_mat_mul=file_diag_mat_mul, # File for diagonal X matrix\n",
    "                        file_matrixmul=file_matrixmul,       # File for matrix X matrix    \n",
    "                        wrkUnit=64,                          # Can be tuned to gain better performance!\n",
    "                        platform_id=platform_id              # Change if more than 1 OpenCL device is available\n",
    "               )\n",
    "\n",
    "# Print calculated stationary matrix\n",
    "if (beVerbose):\n",
    "    print(\"Stationary Matrix\",  lh_func.transistion_matrix)\n",
    "\n",
    "# Initialise GPU\n",
    "lh_func.gpu_chain()\n",
    "\n",
    "print(\"Calculating...\")\n",
    "# Calculate likelihood with CPU and GPU\n",
    "l1 = 0\n",
    "l1 = lh_func.cpu_calculation()\n",
    "l2 = lh_func.gpu_calculation()\n",
    "l3 = lh_func.forward()\n",
    "\n",
    "# Print likelhood outputs.\n",
    "print(\"CPU         \", l1)\n",
    "print(\"GPU         \", l2)\n",
    "print(\"Forward     \", l3)\n",
    "print(\"CPUGPU diff \", l1-l2)\n",
    "print(\"GPUFWD diff \", l2-l3)\n",
    "print(\"CPUGPU perc \", np.abs((l2 - l1) / max(l1, l2))*100)\n",
    "print(\"GPUFWD perc \", np.abs((l3 - l2) / max(l2, l3))*100)\n",
    "\n",
    "HMMLikelihood.check_error(l1, l2)\n",
    " \n",
    "# Example to update different parameters\n",
    "for i in range(1):\n",
    "    print(i,end=\" \")\n",
    "    \n",
    "# Update data used in likelhood, but not changing amount\n",
    "    data = np.random.random([T,3])\n",
    "    data[:,2] = np.round(data[:,2])\n",
    "    lh_func.gpu_update_data(data)\n",
    "    l1 = lh_func.cpu_calculation()\n",
    "    l2 = lh_func.gpu_calculation()\n",
    "    if (beVerbose):\n",
    "        print(\"Update Data\")\n",
    "        print(l1)\n",
    "        print(l2)\n",
    "    HMMLikelihood.check_error(l1, l2)\n",
    "\n",
    "# Update transition matrix\n",
    "    transistion_matrix = HMMLikelihood.calc_transition_matrix(dim)\n",
    "    lh_func.gpu_update_transistion_matrix(transistion_matrix)\n",
    "    l1 = lh_func.cpu_calculation()\n",
    "    l2 = lh_func.gpu_calculation()\n",
    "    if (beVerbose):\n",
    "        print(\"Update Transistion Matrix\")\n",
    "        print(l1)\n",
    "        print(l2)\n",
    "    HMMLikelihood.check_error(l1, l2)\n",
    "\n",
    "# Update Kernel parameters        \n",
    "    kernel = HMMLikelihood.Kernel(\n",
    "               np.random.random([dim,2]), \n",
    "               np.random.random([dim,2]), \n",
    "               np.random.random(dim), \n",
    "               np.random.random(dim), \n",
    "               dim)\n",
    "    lh_func.gpu_update_kernels(kernel())\n",
    "    l1 = lh_func.cpu_calculation()\n",
    "    l2 = lh_func.gpu_calculation()\n",
    "    if (beVerbose):\n",
    "        print(\"Update Kernel\")\n",
    "        print(l1)\n",
    "        print(l2)\n",
    "    HMMLikelihood.check_error(l1, l2)\n",
    "print(\"DONE.\")\n",
    "\n",
    "HMMLikelihood.plot_transition_matrix(lh_func.transistion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:05:08.388007Z",
     "start_time": "2020-04-17T14:05:01.541877Z"
    }
   },
   "outputs": [],
   "source": [
    "# Time each stage of the likelihood computation\n",
    "lh_func.gpu_timing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:05:11.552625Z",
     "start_time": "2020-04-17T14:05:08.389209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get average calculation time for the likelihood using OpenCL\n",
    "%timeit lh_func.gpu_calculation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:05:19.966584Z",
     "start_time": "2020-04-17T14:05:11.554855Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get average computation time using forward algorithm\n",
    "%timeit lh_func.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:05:21.012354Z",
     "start_time": "2020-04-17T14:05:19.967804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Execute forwards algorithm with verbose, showing execution of kernel\n",
    "lh_func.forward(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T09:33:37.710811Z",
     "start_time": "2020-04-16T09:33:37.694201Z"
    }
   },
   "source": [
    "# Usage Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T11:06:21.591568Z",
     "start_time": "2020-04-17T11:06:21.589362Z"
    }
   },
   "source": [
    "## Define Emission Probability Function\n",
    "\n",
    "!It is important to note that currently only a diagonal emission matrix is supported.!\n",
    "\n",
    "We will now define the function used to calculate the emission probability given an observation(data) and the related parameters for the specific state(param).\n",
    "\n",
    "The kernel_function takes two inputs, the function parameters `param` and the observation `data` for a single time instance. The HMMLikelihood library provide a function `testOpenCLFunction` which can be used to test the emission probability function before using it inside the HMM.\n",
    "\n",
    "The `testOpenCLFunction` takes three inputs, the file name of the emission probability function, a list of parameter values and a set of observations for a single time instance. The emission probability function demonstrated here is a Gaussian function with two parameters, mean and sigma, using a single observation. The function is saved in a text file called `testfile.cl`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:05:21.016197Z",
     "start_time": "2020-04-17T14:05:21.013665Z"
    }
   },
   "outputs": [],
   "source": [
    "# The template required for the emission probability function\n",
    "# Currently populated with a Gaussian function.\n",
    "code = \"\"\"\n",
    "float kernel_function(float* param, float* data)  \n",
    "{\n",
    "    /* Add User Function Here */\n",
    "    \n",
    "    float f;\n",
    "    float mu_x    = param[0];\n",
    "    float sigma_x = param[1];\n",
    "\n",
    "    float x = data[0];\n",
    "\n",
    "    float b1 = pown( (x - mu_x) / sigma_x, 2  );\n",
    "    float b2 = 1 / ( sigma_x * sqrt(2 * M_PI) );\n",
    "\n",
    "    f = b2 * exp(-0.5 * b1);\n",
    "    return f;\n",
    "    /* Can only return a single value */\n",
    "}\n",
    "\"\"\"\n",
    "# Write the opencl text file, this file can be edited directly with a text editor if required.\n",
    "file = open(\"./testfile.cl\",\"w\")\n",
    "file.write(code)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:05:21.038153Z",
     "start_time": "2020-04-17T14:05:21.017682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Here we can test the Gaussian function with \n",
    "mean=0\n",
    "sigma=1 \n",
    "# with data point at \n",
    "dpoint = 0.1\n",
    "\n",
    "param = [mean, sigma]\n",
    "data  = [dpoint]\n",
    "print(HMMLikelihood.testOpenCLFunction(\"./testfile.cl\", param, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:05:21.047798Z",
     "start_time": "2020-04-17T14:05:21.039489Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can verify our Gaussian implementation using scipy function\n",
    "import scipy\n",
    "scipy.stats.norm.pdf(dpoint,mean,sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:05:21.055116Z",
     "start_time": "2020-04-17T14:05:21.049061Z"
    }
   },
   "outputs": [],
   "source": [
    "# It is observed that the accuracy of the scipy function and the OpenCL \n",
    "# function differ. The OpenCL function is limited to a float32. \n",
    "# We can demonstrate the loss in accuracy.\n",
    "\n",
    "clf = HMMLikelihood.testOpenCLFunction(\"testfile.cl\", param, data)[0]\n",
    "scf = scipy.stats.norm.pdf(dpoint,mean,sigma)\n",
    "print(\"Percentage loss: \", np.abs(clf - scf) / scf * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up an HMM Chain\n",
    "\n",
    "An HMM chain with 20 states and sequence length of 1000 is created. For this example the previous emission probability function is used. Just as an example the data, transition matrix and kernel parameters for each state is randomized.\n",
    "\n",
    "The class is initialised using the `HMMLikelihood.Likelihood` and set to the variable `lh_func`. The forward algorithm using OpenCL can be executed by `lh_func.gpu_calculation()` providing the likelihood of the chain. The observational data can be updated with `lh_func.gpu_update_data(<data>)`. The transistion matrix can be updated through `lh_func.gpu_update_transistion_matrix(<transistion_matrix>)`. The kernel parameters can be updated through  `lh_func.gpu_update_kernels(<kernel>)`. It must be noted that changing either the number of states of time sequence length would require the initialisation of a new `HMMLikelihood.Likelihood` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:05:21.148660Z",
     "start_time": "2020-04-17T14:05:21.056163Z"
    }
   },
   "outputs": [],
   "source": [
    "# General Testing Block\n",
    "# Length of sequence in HMM chain\n",
    "T = 1000\n",
    "# Number of states\n",
    "dim = 20\n",
    "# Number of observations per time instance\n",
    "dim_observations = 1\n",
    "# Number of paramaters in Emission Probability Function\n",
    "n_params = 2\n",
    "\n",
    "# Files to opencl kernels\n",
    "file_diag_kernel = \"./testfile.cl\"\n",
    "\n",
    "# Calculate random transistion matrix\n",
    "transistion_matrix = HMMLikelihood.calc_transition_matrix(dim)\n",
    "\n",
    "#Generate random data with dimension of dim_observations\n",
    "data = np.random.random([T,dim_observations])\n",
    "\n",
    "# Generate kernel with random initialisations\n",
    "# The Gaussian kernel uses two parameters\n",
    "kernel = np.random.random((dim, n_params))\n",
    "\n",
    "# Create likelhood function\n",
    "lh_func = HMMLikelihood.Likelihood(\n",
    "                        data,                                # Data points  \n",
    "                        transistion_matrix,                  # Transistion matrix initial \n",
    "                        kernel,                              # Kernel parameters\n",
    "                        file_diag_kernel=file_diag_kernel,   # File to probability function\n",
    "                        wrkUnit=64,                         # Can be played around to increase speed\n",
    "                        platform_id=0                        # OpenCL platform selection\n",
    "               )\n",
    "\n",
    "# Initialise GPU\n",
    "lh_func.gpu_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:05:21.155969Z",
     "start_time": "2020-04-17T14:05:21.150120Z"
    }
   },
   "outputs": [],
   "source": [
    "# Execute OpenCL HMM chain forward algorithm\n",
    "lh_func.gpu_calculation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:05:22.978083Z",
     "start_time": "2020-04-17T14:05:21.157452Z"
    }
   },
   "outputs": [],
   "source": [
    "%timeit lh_func.gpu_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM Optimisation using MCMC\n",
    "\n",
    "For more detail on the HMM and the MCMC see the paper *A 1000-fold Acceleration of Hidden Markov Model Fitting using Graphical Processing Units, with application to Nonvolcanic Tremor Classification* https://arxiv.org/abs/2003.03508\n",
    "\n",
    "The data provided with the repository is generated shokoku region data and not the real data used within the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:07:18.750971Z",
     "start_time": "2020-04-17T14:07:13.794723Z"
    }
   },
   "outputs": [],
   "source": [
    "import pytwalk\n",
    "###########################################################\n",
    "# User Defined\n",
    "###########################################################\n",
    "# Select OpenCL Kernels\n",
    "file_diag_kernel = \"../../HMMLikelihood/prob_function.cl\"\n",
    "# Number of States in model \n",
    "dim = 25\n",
    "# Limit number of timesteps(chain sequence length)\n",
    "limit_chain = True\n",
    "chain_limit = 1000\n",
    "\n",
    "###########################################################\n",
    "# Read Data\n",
    "###########################################################\n",
    "locations = pd.read_csv(\"../../data/shokoku_locations_fake.csv\", index_col=False) #Geo location\n",
    "df_locations = locations.drop(locations.columns[0], axis=1)\n",
    "\n",
    "observations = pd.read_csv(\"../../data/shokoku_observations_fake.csv\", index_col=False) #Binary indicator\n",
    "df_observations = observations.drop(observations.columns[0], axis=1)\n",
    "\n",
    "df_data = pd.concat([df_locations, df_observations],  axis=1)\n",
    "data = df_data.values\n",
    "data = np.ascontiguousarray(data)\n",
    "update_data = data[0,0:2]\n",
    "# normalise data\n",
    "for i in range(data.shape[0]):\n",
    "    if data[i,2]>0.5:\n",
    "        update_data = data[i,0:2]\n",
    "    if data[i,2]<0.5:\n",
    "        data[i,0:2] = update_data\n",
    "\n",
    "# Limits for Branch Support\n",
    "data_min_0 = data[:,0].min()\n",
    "data_max_0 = data[:,0].max()\n",
    "data_min_1 = data[:,1].min()\n",
    "data_max_1 = data[:,1].max()\n",
    "        \n",
    "# Use only first <chain_limit> timesteps of data\n",
    "if (limit_chain):\n",
    "    data = data[:chain_limit]\n",
    "\n",
    "\n",
    "\n",
    "#Number of data points observed in time\n",
    "T = data.shape[0]\n",
    "\n",
    "print(\"[Dim: {}, T: {}, Kernel param:{}]\".format(dim, T, 6))\n",
    "\n",
    "# Generate random transistion matrix\n",
    "transistion_matrix = HMMLikelihood.calc_transition_matrix(dim)\n",
    "  \n",
    "# Initialise kernel with initial values\n",
    "# Use random kernel initial values\n",
    "kernel = HMMLikelihood.Kernel(\n",
    "           np.random.random([dim,2]), \n",
    "           np.random.random([dim,2]), \n",
    "           np.random.random(dim), \n",
    "           np.random.random(dim), \n",
    "           dim)\n",
    "\n",
    "###########################################################\n",
    "# Initialise Likelhood function\n",
    "###########################################################\n",
    "lh_func = HMMLikelihood.Likelihood(\n",
    "                     data,                                # Data points  \n",
    "                     transistion_matrix,                  # Transistion matrix initial\n",
    "                     kernel(),                            # Kernel parameters\n",
    "                     file_diag_kernel=file_diag_kernel,   # File to probability function\n",
    "                     )\n",
    "# Initialise GPU\n",
    "lh_func.gpu_chain()\n",
    "\n",
    "###########################################################\n",
    "# Define MCMC\n",
    "###########################################################\n",
    "def log_prior(x):\n",
    "    # Moet nog dink oor watse prior as daar min data is\n",
    "    x =np.abs(x)\n",
    "    temp = np.reshape(x[:dim**2], [dim,dim]) + 0.0001\n",
    "    diagonal = 1 - ( np.sum(np.abs(temp), axis=1) - np.diag(np.abs(temp)))\n",
    "    np.fill_diagonal(temp, diagonal)\n",
    "    log_prior = 0\n",
    "    for i in range(0,dim):\n",
    "        log_prior += sps.dirichlet.logpdf(temp[i,:], alpha=0.99*np.ones(dim))\n",
    "    return log_prior\n",
    "\n",
    "def log_posterior(x):\n",
    "    return -(logL(x)) #log_prior(x)) \n",
    "\n",
    "def logL(x):\n",
    "    # Take first dim^2 parameters and form transition_matrix\n",
    "    P = np.reshape(x[:dim**2], [dim,dim])\n",
    "    diagonal = 1 - ( np.sum(np.abs(P), axis=1) - np.diag(np.abs(P)))\n",
    "    np.fill_diagonal(P, diagonal)\n",
    "    transistion_matrix = P\n",
    "    \n",
    "    # Take rest of parameters to define kernels\n",
    "    x_sub = x[dim**2:]\n",
    "    start_params_sub = start_params[dim**2:]\n",
    "    kernel = HMMLikelihood.Kernel(np.reshape(x_sub[:2*dim],[dim,2]), np.reshape(x_sub[2*dim:4*dim],[dim,2]),\n",
    "           x_sub[4*dim:5*dim], x_sub[5*dim:6*dim], dim)\n",
    "    \n",
    "    # Update Kernels and Transtion matrix\n",
    "    lh_func.gpu_update_kernels(kernel()) \n",
    "    lh_func.gpu_update_transistion_matrix(transistion_matrix)\n",
    "\n",
    "    # Calculate likelihodd\n",
    "    test = lh_func.gpu_calculation()\n",
    " \n",
    "    # Bottom limit, prefent NaN\n",
    "    if np.isinf(test) or np.isnan(test):\n",
    "        loglikelihood = -1000000\n",
    "    else:\n",
    "        loglikelihood = test\n",
    "    return loglikelihood\n",
    "\n",
    "def generate_params(dim):\n",
    "    \"\"\"\n",
    "        Generate array of random parameters to be used within the MCMC\n",
    "    \"\"\"\n",
    "    params = np.random.random(6*dim + dim**2)\n",
    "    params[0:dim**2] = np.reshape(HMMLikelihood.calc_transition_matrix(dim), dim**2)\n",
    "    index_1 = T*np.random.random(dim)\n",
    "    index_2 = T*np.random.random(dim)\n",
    "    params[dim**2:(dim**2 + 2*dim):2] = data[index_1.astype(int),0]\n",
    "    params[(dim**2+1):(dim**2 + 2*dim):2] = data[index_2.astype(int),1]\n",
    "    \n",
    "    #sort the means\n",
    "    x_sub = params[dim**2:dim**2+2*dim]\n",
    "    mean = np.reshape(x_sub,[dim,2])\n",
    "    dist = np.linalg.norm(mean, axis=1)\n",
    "    params[dim**2:dim**2+2*dim] = np.ndarray.flatten(mean[np.argsort(dist)])\n",
    "    return params\n",
    "\n",
    "def gv(x,string):\n",
    "    if string == \"trans\":\n",
    "        y = x[0:dim**2]\n",
    "    if string == \"mean\":\n",
    "        y = x[dim**2:(dim**2+2*dim)]\n",
    "    if string == \"mean_0\":\n",
    "        y = x[dim**2:(dim**2+2*dim):2]\n",
    "    if string == \"mean_1\":\n",
    "        y = x[(dim**2+1):(dim**2+2*dim):2] \n",
    "    if string == \"sig\":\n",
    "        y = x[dim**2+2*dim:(dim**2+4*dim)]\n",
    "    if string == \"rho\":\n",
    "        y = x[dim**2+4*dim:(dim**2+5*dim)]\n",
    "    if string == \"p\":\n",
    "        y = x[dim**2+5*dim:(dim**2+6*dim)]\n",
    "    return y\n",
    "\n",
    "def BranchSupp(x): \n",
    "    global data_min_0, data_max_0\n",
    "    global data_min_1, data_max_1\n",
    "    X = np.reshape(x[:dim**2], [dim,dim])\n",
    "    # Find diagonal coefficients\n",
    "    D = np.diag(np.abs(X)) \n",
    "    # Find row sum without diagonal\n",
    "    S = np.sum(np.abs(X), axis=1) - D \n",
    "    \n",
    "    x_sub = x[dim**2:]\n",
    "    flag_trans = (all(0<gv(x,\"trans\")+0.0001)&all(gv(x,\"trans\")<=1)&all(1 > S))\n",
    "    flag_mean_0 = (all(data_min_0<=gv(x,\"mean_0\"))&all(gv(x,\"mean_0\")<=data_max_0))\n",
    "    flag_mean_1 = (all(data_min_1<=gv(x,\"mean_1\")+0.1)&all(gv(x,\"mean_1\")<=data_max_1+0.1))\n",
    "\n",
    "    flag_sig = (all(0<=gv(x,\"sig\"))&all(gv(x,\"sig\")<=1))\n",
    "    \n",
    "    flag_rho = (all(-1<=gv(x,\"rho\"))&all(gv(x,\"rho\")<=1))\n",
    "    \n",
    "    flag_p = (all(0<=gv(x,\"p\"))&all(gv(x,\"p\")<=1))\n",
    "    return (flag_trans&flag_mean_0&flag_mean_1&flag_sig&flag_rho&flag_p)\n",
    "\n",
    "start_params = generate_params(dim)\n",
    "\n",
    "#Starting parameters for MCMC chains\n",
    "start_params_1 = start_params \n",
    "start_params_2 = start_params*0.999+0.000001 \n",
    "\n",
    "#Initialize and run MCMC\n",
    "Tree_Inference = pytwalk.pytwalk( n=6*dim + dim**2, U=log_posterior, Supp=BranchSupp)\n",
    "Tree_Inference.Run(T=1000, x0=start_params_1, xp0=start_params_2 )\n",
    "#########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:07:20.425710Z",
     "start_time": "2020-04-17T14:07:20.253435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print chain analysis\n",
    "Tree_Inference.Ana()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:07:22.028401Z",
     "start_time": "2020-04-17T14:07:21.872662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print transition matrix\n",
    "x = Tree_Inference.Output\n",
    "optimal_ind = np.argpartition(x[int(x.shape[0] * 0.2):,-1], -5)[-5:]\n",
    "optimal_pos = np.argmin(x[int(x.shape[0] * 0.2):,-1])\n",
    "P = np.reshape(x[optimal_pos,0:(dim)**2], [dim,dim])\n",
    "HMMLikelihood.plot_transition_matrix(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-17T14:07:50.630284Z",
     "start_time": "2020-04-17T14:07:23.459339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print distributions of parameters.\n",
    "print(\"Likelihood\")\n",
    "x = Tree_Inference.Output\n",
    "y = x[int(x.shape[0] * 0.2):,-1]\n",
    "plt.hist(y[y<100000], bins = 100)\n",
    "plt.show()\n",
    "print(\"Parameters\")\n",
    "for i in range(dim):\n",
    "    fig, ax = plt.subplots(2,3, figsize=(15,7))\n",
    "    ax = ax.flatten()\n",
    "    print(\"Kernel {}\".format(i + 1))\n",
    "    for j in range(6):\n",
    "        ax[j].hist(x[int(x.shape[0]*0.2):,dim**2 + i*6 + j], bins = 100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
